# -*- coding: utf-8 -*-
"""tfidf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xd-8Rsfd7diPdEtq0ukq772tQ57zzGMP
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

def read_data():

  data = pd.read_excel('tfidf.xlsx')
  data = data.loc[:,['name','reviews.text']]
  print('Original Data:\n', data.tail())
  document = data.loc[:,['name']]
  document = document.drop_duplicates()
  print('The Documet number:',len(document))
  print('Original Document:\n', document.tail())
  return data, document

data, document = read_data()

def search_document(current_document, data):
  '''
  输入：原始数据集
  输出：当前产品的所有文字

  '''
  record = ''
  for i in range(len(data)):
    if data['name'][i]==current_document:
      record = record + data['reviews.text'][i]
  return record
def generate_document(data, document):
  '''
  得到每个产品的所有文本内容，相当于吧每个产品看作一个document，生成该数据集并保存
  '''
  record_list = []
  print('===============================')
  print('Processing Progress')  
  for i, current_document in enumerate(document['name']):
    record_list.append([i, current_document, search_document(current_document, data)])
    if i%10 == 0:
      print('%d/%d'%(i, len(document)))
  record_df = pd.DataFrame(record_list)
  record_df.to_csv('sample.csv')
  return record_df
  print('New Data:\n', record_df.tail())

import sys,codecs
from sklearn import feature_extraction
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer

dataFile = 'sample.csv'
top_k = 10
data1 = pd.read_csv(dataFile)

def getKeywords_tfidf(data,topK):
    idList, titleList, abstractList = data['0'], data['1'], data['2']
    corpus = [] # 将所有文档输出到一个list中，一行就是一个文档
    for index in range(len(idList)):
        text = '%s。%s' % (titleList[index], abstractList[index]) # 拼接标题和摘要
        corpus.append(text)

    # 1、构建词频矩阵，将文本中的词语转换成词频矩阵
    vectorizer = CountVectorizer(stop_words = 'english')
    X = vectorizer.fit_transform(corpus) # 词频矩阵,a[i][j]:表示j词在第i个文本中的词频
    # 2、统计每个词的tf-idf权值
    transformer = TfidfTransformer()
    tfidf = transformer.fit_transform(X)
    # 3、获取词袋模型中的关键词
    word = vectorizer.get_feature_names_out()
    # 4、获取tf-idf矩阵，a[i][j]表示j词在i篇文本中的tf-idf权重
    weight = tfidf.toarray()
    # 5、打印词语权重
    ids, titles, keys = [], [], []
    for i in range(len(weight)):
        if i%10 == 0:
          print('deal with the %d/%d document'%(i,len(idList)))
        ids.append(idList[i])
        titles.append(titleList[i])
        df_word,df_weight = [],[] # 当前文章的所有词汇列表、词汇对应权重列表
        for j in range(len(word)):
            #print(word[j],weight[i][j])
            df_word.append(word[j])
            df_weight.append(weight[i][j])
        df_word = pd.DataFrame(df_word,columns=['word'])
        df_weight = pd.DataFrame(df_weight,columns=['weight'])
        word_weight = pd.concat([df_word, df_weight], axis=1) # 拼接词汇列表和权重列表
        word_weight = word_weight.sort_values(by="weight",ascending = False) # 按照权重值降序排列
        keyword = np.array(word_weight['word']) # 选择词汇列并转成数组格式
        word_split = [keyword[x] for x in range(0,topK)] # 抽取前topK个词汇作为关键词 
        keys.append(word_split)

    result = pd.DataFrame({"id": ids, "title": titles, "key": keys},columns=['id','title','key'])
    return result

r = getKeywords_tfidf(data1,30)